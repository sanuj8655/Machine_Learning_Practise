{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f84cc12a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all required packages\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fc894e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the data\n",
    "df = pd.read_csv('Wine.csv')\n",
    "# print(df.head())\n",
    "# print(len(df.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30a6d2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# decide x and y\n",
    "x = df.drop('Customer_Segment', axis=1)\n",
    "y = df['Customer_Segment']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "795d0673",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c4948a",
   "metadata": {},
   "source": [
    "### QDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1eb4b249",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Alcohol  Malic_Acid   Ash  Ash_Alcanity  Magnesium  Total_Phenols  \\\n",
      "172    14.16        2.51  2.48          20.0         91           1.68   \n",
      "24     13.50        1.81  2.61          20.0         96           2.53   \n",
      "145    13.16        3.57  2.15          21.0        102           1.50   \n",
      "156    13.84        4.12  2.38          19.5         89           1.80   \n",
      "90     12.08        1.83  2.32          18.5         81           1.60   \n",
      "117    12.42        1.61  2.19          22.5        108           2.00   \n",
      "137    12.53        5.51  2.64          25.0         96           1.79   \n",
      "83     13.05        3.86  2.32          22.5         85           1.65   \n",
      "148    13.32        3.24  2.38          21.5         92           1.93   \n",
      "112    11.76        2.68  2.92          20.0        103           1.75   \n",
      "76     13.03        0.90  1.71          16.0         86           1.95   \n",
      "105    12.42        2.55  2.27          22.0         90           1.68   \n",
      "171    12.77        2.39  2.28          19.5         86           1.39   \n",
      "157    12.45        3.03  2.64          27.0         97           1.90   \n",
      "28     13.87        1.90  2.80          19.4        107           2.95   \n",
      "20     14.06        1.63  2.28          16.0        126           3.00   \n",
      "53     13.77        1.90  2.68          17.1        115           3.00   \n",
      "27     13.30        1.72  2.14          17.0         94           2.40   \n",
      "149    13.08        3.90  2.36          21.5        113           1.41   \n",
      "37     13.05        1.65  2.55          18.0         98           2.45   \n",
      "42     13.88        1.89  2.59          15.0        101           3.25   \n",
      "168    13.58        2.58  2.69          24.5        105           1.55   \n",
      "126    12.43        1.53  2.29          21.5         86           2.74   \n",
      "122    12.42        4.43  2.73          26.5        102           2.20   \n",
      "109    11.61        1.35  2.70          20.0         94           2.74   \n",
      "29     14.02        1.68  2.21          16.0         96           2.65   \n",
      "102    12.34        2.45  2.46          21.0         98           2.56   \n",
      "49     13.94        1.73  2.27          17.4        108           2.88   \n",
      "86     12.16        1.61  2.31          22.8         90           1.78   \n",
      "79     12.70        3.87  2.40          23.0        101           2.83   \n",
      "141    13.36        2.56  2.35          20.0         89           1.40   \n",
      "23     12.85        1.60  2.52          17.8         95           2.48   \n",
      "176    13.17        2.59  2.37          20.0        120           1.65   \n",
      "85     12.67        0.98  2.24          18.0         99           2.20   \n",
      "78     12.33        0.99  1.95          14.8        136           1.90   \n",
      "5      14.20        1.76  2.45          15.2        112           3.27   \n",
      "\n",
      "     Flavanoids  Nonflavanoid_Phenols  Proanthocyanins  Color_Intensity   Hue  \\\n",
      "172        0.70                  0.44             1.24         9.700000  0.62   \n",
      "24         2.61                  0.28             1.66         3.520000  1.12   \n",
      "145        0.55                  0.43             1.30         4.000000  0.60   \n",
      "156        0.83                  0.48             1.56         9.010000  0.57   \n",
      "90         1.50                  0.52             1.64         2.400000  1.08   \n",
      "117        2.09                  0.34             1.61         2.060000  1.06   \n",
      "137        0.60                  0.63             1.10         5.000000  0.82   \n",
      "83         1.59                  0.61             1.62         4.800000  0.84   \n",
      "148        0.76                  0.45             1.25         8.420000  0.55   \n",
      "112        2.03                  0.60             1.05         3.800000  1.23   \n",
      "76         2.03                  0.24             1.46         4.600000  1.19   \n",
      "105        1.84                  0.66             1.42         2.700000  0.86   \n",
      "171        0.51                  0.48             0.64         9.899999  0.57   \n",
      "157        0.58                  0.63             1.14         7.500000  0.67   \n",
      "28         2.97                  0.37             1.76         4.500000  1.25   \n",
      "20         3.17                  0.24             2.10         5.650000  1.09   \n",
      "53         2.79                  0.39             1.68         6.300000  1.13   \n",
      "27         2.19                  0.27             1.35         3.950000  1.02   \n",
      "149        1.39                  0.34             1.14         9.400000  0.57   \n",
      "37         2.43                  0.29             1.44         4.250000  1.12   \n",
      "42         3.56                  0.17             1.70         5.430000  0.88   \n",
      "168        0.84                  0.39             1.54         8.660000  0.74   \n",
      "126        3.15                  0.39             1.77         3.940000  0.69   \n",
      "122        2.13                  0.43             1.71         2.080000  0.92   \n",
      "109        2.92                  0.29             2.49         2.650000  0.96   \n",
      "29         2.33                  0.26             1.98         4.700000  1.04   \n",
      "102        2.11                  0.34             1.31         2.800000  0.80   \n",
      "49         3.54                  0.32             2.08         8.900000  1.12   \n",
      "86         1.69                  0.43             1.56         2.450000  1.33   \n",
      "79         2.55                  0.43             1.95         2.570000  1.19   \n",
      "141        0.50                  0.37             0.64         5.600000  0.70   \n",
      "23         2.37                  0.26             1.46         3.930000  1.09   \n",
      "176        0.68                  0.53             1.46         9.300000  0.60   \n",
      "85         1.94                  0.30             1.46         2.620000  1.23   \n",
      "78         1.85                  0.35             2.76         3.400000  1.06   \n",
      "5          3.39                  0.34             1.97         6.750000  1.05   \n",
      "\n",
      "     OD280  Proline  \n",
      "172   1.71      660  \n",
      "24    3.82      845  \n",
      "145   1.68      830  \n",
      "156   1.64      480  \n",
      "90    2.27      480  \n",
      "117   2.96      345  \n",
      "137   1.69      515  \n",
      "83    2.01      515  \n",
      "148   1.62      650  \n",
      "112   2.50      607  \n",
      "76    2.48      392  \n",
      "105   3.30      315  \n",
      "171   1.63      470  \n",
      "157   1.73      880  \n",
      "28    3.40      915  \n",
      "20    3.71      780  \n",
      "53    2.93     1375  \n",
      "27    2.77     1285  \n",
      "149   1.33      550  \n",
      "37    2.51     1105  \n",
      "42    3.56     1095  \n",
      "168   1.80      750  \n",
      "126   2.84      352  \n",
      "122   3.12      365  \n",
      "109   3.26      680  \n",
      "29    3.59     1035  \n",
      "102   3.38      438  \n",
      "49    3.10     1260  \n",
      "86    2.26      495  \n",
      "79    3.13      463  \n",
      "141   2.47      780  \n",
      "23    3.63     1015  \n",
      "176   1.62      840  \n",
      "85    3.16      450  \n",
      "78    2.31      750  \n",
      "5     2.85     1450  \n",
      "[3 1 3 3 2 2 3 2 3 2 2 2 3 3 1 1 1 1 3 1 1 3 2 2 2 1 2 1 2 2 3 1 3 2 2 1]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "qda = QuadraticDiscriminantAnalysis()\n",
    "\n",
    "# extract features from train\n",
    "a = qda.fit(x_train, y_train).predict(x_test)\n",
    "print(x_test)\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cbcca00",
   "metadata": {},
   "source": [
    "### data cleansing process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45557418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look out the missing data\n",
    "# use the correct data type\n",
    "# add new columns if needed\n",
    "# drop existing columns if needed\n",
    "\n",
    "# scale the features\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# scale the x_train features\n",
    "x_train = scaler.fit_transform(x_train)\n",
    "\n",
    "# scale the x_test features\n",
    "x_test = scaler.fit_transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0faf9d8",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "92053d15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11  0  0]\n",
      " [ 0 13  1]\n",
      " [ 0  0 11]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "\n",
    "# create a model\n",
    "model = LogisticRegressionCV(max_iter=1000)\n",
    "\n",
    "# train the model\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# predict the values from x_test\n",
    "y_prediction = model.predict(x_test)\n",
    "\n",
    "# evaluation\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\n",
    "\n",
    "print(confusion_matrix(y_test, y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a482a9c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00        11\n",
      "           2       1.00      0.93      0.96        14\n",
      "           3       0.92      1.00      0.96        11\n",
      "\n",
      "    accuracy                           0.97        36\n",
      "   macro avg       0.97      0.98      0.97        36\n",
      "weighted avg       0.97      0.97      0.97        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "419f3ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9722222222222222\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, y_prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "73239e30",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d406234",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
